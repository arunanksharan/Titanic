{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning Checklist**\n",
    "1. Frame the problem and look at the big picture.\n",
    "2. Get the data.\n",
    "3. Explore the data to gain insights.\n",
    "4. Prepare the data to better expose the underlying data patterns to Machine Learning algorithms.\n",
    "5. Explore many different models and short-list the best ones.\n",
    "6. Fine-tune your models and combine them into a great solution.\n",
    "7. Present your solution.\n",
    "8. Launch, monitor, and maintain your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Frame the problem and look at the big picture**\n",
    "- Goal: Predict the survival of the passengers in test set.\n",
    "- Objective: Creation of a supervised binary classifier (Survived: 1, Did Not Survive: 0)\n",
    "- Measurement of Performance: Create a confusion matrix and compute Accuracy, Recall, Precision and f-score.\n",
    "- List the assumptions.\n",
    "\n",
    "**2. Get the data**\n",
    "- Completed\n",
    "\n",
    "**3. Explore the data to get insights**\n",
    "- Study each attribute and its characteristics:\n",
    "    \n",
    "    * Name\n",
    "    \n",
    "    * Type (categorical, int/float, bounded/unbounded, text, structured, etc.)\n",
    "    \n",
    "    * % of missing values\n",
    "    \n",
    "    * Noisiness and type of noise (stochastic, outliers, rounding errors, etc.)\n",
    "    \n",
    "    * Possibly useful for the task?\n",
    "    \n",
    "    * Type of distribution (Gaussian, uniform, logarithmic, etc.)\n",
    "\n",
    "- For supervised learning tasks, identify the target attribute(s).\n",
    "- Visualize the data.\n",
    "- Study the correlations between attributes.\n",
    "- Study how you would solve the problem manually.\n",
    "- Identify the promising transformations you may want to apply.\n",
    "- Identify extra data that would be useful (go back to “Get the Data” on page 498).\n",
    "- Document what you have learned.\n",
    "\n",
    "**4. Prepare the data to better expose the underlying data patterns to Machine Learning algorithms**\n",
    "- Work on copies of the data (keep the original dataset intact).\n",
    "\n",
    "- Write functions for all data transformations you apply, for five reasons:\n",
    "\n",
    "    * So you can easily prepare the data the next time you get a fresh dataset\n",
    "    \n",
    "    * So you can apply these transformations in future projects\n",
    "    \n",
    "    * To clean and prepare the test set\n",
    "    \n",
    "    * To clean and prepare new data instances once your solution is live\n",
    "    \n",
    "    * To make it easy to treat your preparation choices as hyperparameters\n",
    "\n",
    "- Data cleaning:\n",
    "\n",
    "    * Fix or remove outliers (optional).\n",
    "    \n",
    "    * Fill in missing values (e.g., with zero, mean, median...) or drop their rows (or columns).\n",
    "    \n",
    "- Feature selection (optional):\n",
    "\n",
    "    * Drop the attributes that provide no useful information for the task.\n",
    "\n",
    "- Feature engineering, where appropriate: \n",
    "\n",
    "    * Discretize continuous features.\n",
    "\n",
    "    * Decompose features (e.g., categorical, date/time, etc.).\n",
    "\n",
    "    * Add promising transformations of features (e.g., log(x), sqrt(x), x^2, etc.).\n",
    "\n",
    "    * Aggregate features into promising new features.\n",
    "    \n",
    "- Feature scaling: standardize or normalize features.\n",
    "\n",
    "**5. Explore many different models and short-list the best ones**\n",
    "\n",
    "**6. Fine-tune your models and combine them into a great solution**\n",
    "\n",
    "**7. Present your solution**\n",
    "\n",
    "**8. Launch, monitor, and maintain your system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "#%gui\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I) Exploring PassengerId**\n",
    "1. Check if number all PassengerIds are unique\n",
    "2. Checklist:\n",
    "    - Name: PassengerId\n",
    "\n",
    "    - Type (categorical, int/float, bounded/unbounded, text, structured, etc.): Categorical/Index\n",
    "\n",
    "    - % of missing values: 0\n",
    "\n",
    "    - Noisiness and type of noise (stochastic, outliers, rounding errors, etc.): No\n",
    "\n",
    "    - Possibly useful for the task?: Yes. Unique identifier for a passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of train: (Rows, Columns)\n",
    "print(\"Shape of train dataset is: Rows %s, Columns %s\" %(train.shape))\n",
    "# R Command: len(unique(x))\n",
    "print(\"Number of unique PassengerIds is: %s\" %(len(train['PassengerId'].unique())))\n",
    "\n",
    "# Since, number of rows and number of unique PassengerIds are the same, it means there are no duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**II) Survived**:\n",
    "1. Checklist:\n",
    "    - Name: Survived\n",
    "\n",
    "    - Type (categorical, int/float, bounded/unbounded, text, structured, etc.): Categorical, Binary, Survived: 1, Did not survive: 0\n",
    "\n",
    "    - % of missing values: 0\n",
    "\n",
    "    - Noisiness and type of noise (stochastic, outliers, rounding errors, etc.): No\n",
    "\n",
    "    - Possibly useful for the task?: Yes. It is the label/output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts() : Equivalent R Command: table()\n",
    "print(train['Survived'].value_counts())\n",
    "print(train['Survived'].value_counts(normalize=True))\n",
    "\n",
    "# 61% or 549 out of 891 dies. 38% or 342 out of 891 survived.\n",
    "# based on this, survival rate is 38%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R Command: colnames()\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**III) Pclass**\n",
    "1. Checklist:\n",
    "    - Name: Pclass\n",
    "\n",
    "    - Type (categorical, int/float, bounded/unbounded, text, structured, etc.): Categorical with 3 levels: 1,2,3\n",
    "\n",
    "    - % of missing values: 0\n",
    "\n",
    "    - Noisiness and type of noise (stochastic, outliers, rounding errors, etc.): No\n",
    "\n",
    "    - Possibly useful for the task?: Yes. Passengers of different Pclass have different survival rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NAs in Pclass: %s' %(train['Pclass'].isnull().sum()))\n",
    "print(train.groupby('Pclass')['Survived'].value_counts())\n",
    "print((train.groupby('Pclass')['Survived'].value_counts(normalize=True)))\n",
    "\n",
    "# Pclass 1 has highest survival rate at 62.96%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IV) Name**\n",
    "1. Checklist:\n",
    "    - Name: Name\n",
    "\n",
    "    - Type (categorical, int/float, bounded/unbounded, text, structured, etc.): String, May be used as an identifier\n",
    "\n",
    "    - % of missing values: 0\n",
    "\n",
    "    - Noisiness and type of noise (stochastic, outliers, rounding errors, etc.): White spaces, Non-ASCII\n",
    "\n",
    "    - Possibly useful for the task?: Yes. Title (Mr, Miss, Mrs, Master etc) can be extracted for additional information such as social status which may be correlated to higher survival rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NAs in Name: %s' %(train['Name'].isnull().sum()))\n",
    "print(train['Name'])\n",
    "# This will be explored further later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**V) Sex**\n",
    "1. Checklist:\n",
    "\n",
    "    - Name: Sex\n",
    "\n",
    "    - Type (categorical, int/float, bounded/unbounded, text, structured, etc.): String as of now (male, female), Needs to be converted into Categorical with 2 levels: Male - 0, Female - 1\n",
    "\n",
    "    - % of missing values: 0\n",
    "\n",
    "    - Noisiness and type of noise (stochastic, outliers, rounding errors, etc.): No\n",
    "\n",
    "    - Possibly useful for the task?: Yes. Females have significanlty higher survival rates overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('NAs in Sex: %s' %(train['Sex'].isnull().sum()))\n",
    "print(train['Sex'].value_counts())\n",
    "print(train.groupby('Sex')['Survived'].value_counts())\n",
    "print(train.groupby('Sex')['Survived'].value_counts(normalize=True))\n",
    "\n",
    "# There are lesser number of females overall but their survival rate is higher.\n",
    "# Analysis of survival of females by Pclass is performed as below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VI) Pclass and Sex**\n",
    "1. Checklist:\n",
    "\n",
    "    - Name: Pclass and Sex\n",
    "\n",
    "    - Type (categorical, int/float, bounded/unbounded, text, structured, etc.): Categorical\n",
    "\n",
    "    - % of missing values: 0\n",
    "\n",
    "    - Noisiness and type of noise (stochastic, outliers, rounding errors, etc.): No\n",
    "\n",
    "    - Possibly useful for the task?: Yes. Females have significanlty higher survival rates overall in Pclass 1 and Pclass 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['Sex'].value_counts())\n",
    "print(train.groupby(['Pclass', 'Sex'])['Survived'].value_counts())\n",
    "print(train.groupby(['Pclass', 'Sex'])['Survived'].value_counts(normalize=True))\n",
    "# Pclass 1: 96.8% females have survived whereas only 63.1% males survived.\n",
    "# Pclass 2: 92.1% females have survived whereas 84.2% males have surived.\n",
    "# Pclass 3: 50% females have survived whereas 86.4% males have survived.\n",
    "# This clearly indicates that female with Pclass 1 and Pclass 2 have very high probability of survival.\n",
    "# This will be useful feature later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VII) Age**\n",
    "1. Checklist:\n",
    "\n",
    "    - Name: Age\n",
    "\n",
    "    - Type (categorical, int/float, bounded/unbounded, text, structured, etc.): Continuous, Float, Needs to be converted into Categorical with pd.cut i.e. into Age Bands (0-15, 15-30, 30-45, 45-60, 60-75, >75), Range is from 0.42 to 80.0.\n",
    "\n",
    "    - % of missing values: 177, Will need imputation as this is quite high.\n",
    "\n",
    "    - Noisiness and type of noise (stochastic, outliers, rounding errors, etc.): No outliers, NAs present in significant number.\n",
    "\n",
    "    - Possibly useful for the task?: Yes, maybe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age is a continuous variable. It will be explored as part of data visualization.\n",
    "print(\"NAs in Age: %s\" %(train['Age'].isnull().sum()))\n",
    "#print(np.nanmedian(train['Age']))\n",
    "print(max(train['Age']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VIII) SibSp and Parch**\n",
    "1. Checklist:\n",
    "\n",
    "    - Name: SibSp, Parch\n",
    "\n",
    "    - Type (categorical, int/float, bounded/unbounded, text, structured, etc.): Integer/Number, Can be considered Categorical\n",
    "\n",
    "    - % of missing values: 0, 0\n",
    "\n",
    "    - Noisiness and type of noise (stochastic, outliers, rounding errors, etc.): \n",
    "\n",
    "    - Possibly useful for the task?: Yes, maybe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NAs in SibSp: %s\" %(train['SibSp'].isnull().sum()))\n",
    "print(\"NAs in Parch: %s\" %(train['Parch'].isnull().sum()))\n",
    "print(train['SibSp'].value_counts())\n",
    "print(train.groupby('SibSp')['Survived'].value_counts())\n",
    "print(train.groupby('SibSp')['Survived'].value_counts(normalize=True))\n",
    "print(train.groupby(['SibSp','Sex'])['Survived'].value_counts())\n",
    "print(train.groupby(['SibSp','Sex'])['Survived'].value_counts(normalize=True))\n",
    "# Overall, if you have 1 sibling/spouse, you have highest chance of survival.\n",
    "# If you are a female with 0,1,2 sibling/spouse, you have more than 70% chance of survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parch\n",
    "print(train.groupby('Parch')['Survived'].value_counts())\n",
    "print(train.groupby('Parch')['Survived'].value_counts(normalize=True))\n",
    "\n",
    "#SibSp and Parch can be added/combined to form a single column of family."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IX) Ticket**\n",
    "1. Checklist:\n",
    "\n",
    "    - Name: Ticket\n",
    "\n",
    "    - Type (categorical, int/float, bounded/unbounded, text, structured, etc.): Integer/Number, Can be considered Categorical\n",
    "\n",
    "    - % of missing values: 0, 0\n",
    "\n",
    "    - Noisiness and type of noise (stochastic, outliers, rounding errors, etc.): \n",
    "\n",
    "    - Possibly useful for the task?: No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['Ticket'].isnull().sum()) # No NA present\n",
    "print(train[['Ticket', 'Pclass','Survived']])\n",
    "# Ticket number does not appear to be providing any significant information and will be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**X) Fare**\n",
    "1. Checklist:\n",
    "\n",
    "    - Name: Fare\n",
    "\n",
    "    - Type (categorical, int/float, bounded/unbounded, text, structured, etc.): Float, Continuous, Needs to be converted into categorical or Fare Bands\n",
    "\n",
    "    - % of missing values: 0\n",
    "\n",
    "    - Noisiness and type of noise (stochastic, outliers, rounding errors, etc.): \n",
    "\n",
    "    - Possibly useful for the task?: Yes, maybe. Correlation with Pclass needs to be studied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NAs in Fare: %s' %(train['Fare'].isnull().sum()))\n",
    "print(train[['Fare', 'Pclass', 'Survived']])\n",
    "# Further exploration as part of data visualization where correlation with Pclass will also be determined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XI) Cabin**\n",
    "1. Checklist:\n",
    "\n",
    "    - Name: Cabin\n",
    "\n",
    "    - Type (categorical, int/float, bounded/unbounded, text, structured, etc.): Integer/Number, Can be considered Categorical\n",
    "\n",
    "    - % of missing values: 687\n",
    "\n",
    "    - Noisiness and type of noise (stochastic, outliers, rounding errors, etc.): \n",
    "\n",
    "    - Possibly useful for the task?: No. Needs to be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['Cabin'].isnull().sum()) # 687 NAs out of 891 rows => Will be dropped\n",
    "print(train['Cabin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XI) Embarked**\n",
    "1. Checklist:\n",
    "\n",
    "    - Name: Embarked\n",
    "\n",
    "    - Type (categorical, int/float, bounded/unbounded, text, structured, etc.): Categorical with 3 levels (C,Q,S)\n",
    "\n",
    "    - % of missing values: 2\n",
    "\n",
    "    - Noisiness and type of noise (stochastic, outliers, rounding errors, etc.): NA\n",
    "\n",
    "    - Possibly useful for the task?: Yes, maybe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['Embarked'].isnull().sum()) # 2 NAs\n",
    "print(train.groupby('Embarked')['Survived'].value_counts(normalize=False))\n",
    "print(train.groupby('Embarked')['Survived'].value_counts(normalize=True))\n",
    "print(train.groupby(['Embarked', 'Pclass'])['Survived'].value_counts(normalize=False))\n",
    "print(train.groupby(['Embarked', 'Pclass'])['Survived'].value_counts(normalize=True))\n",
    "print(train[['Embarked','Pclass','Survived']])\n",
    "# Most people embarked from S. Highest urvival: Embarked C and Pclass 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Visualization**\n",
    "1. Distribution to decied upon feature engineering, feature scaling and transformation to be used.\n",
    "2. Correlation between attributes to decide upon feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns\n",
    "#[u'PassengerId', u'Survived', u'Pclass', u'Name', u'Sex', u'Age',\n",
    "#       u'SibSp', u'Parch', u'Ticket', u'Fare', u'Cabin', u'Embarked']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I) PassengerId**\n",
    "- It acts as the index and unique identifier. Visulization is not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**II) Survived**\n",
    "1. Overall Survival Rates: Barplot for levels 0 and 1\n",
    "2. Survival Rates by Sex: Barplot for male and female\n",
    "3. Survival Rates by Pclass: Barplot for 1,2,3\n",
    "4. Survival Rates by Sex for different Pclass: Barplot for male and female on Facet Grid with Pclass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = fig.add_subplot(2,2,1)\n",
    "fig2 = fig.add_subplot(2,2,2)\n",
    "fig3 = fig.add_subplot(2,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([1.5, 3.5, -2, 1.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "fig1.hist(np.random.randn(100), bins=20, color='k', alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XXXXXXXXXXXXXXXXXXXXXXXXX LATER XXXXXXXXXXXXXXXXXXXXXXXXXXXX**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Should be done much later. train and test need to be preprocessed first.\n",
    "**Creating X_train, X_test and y_train, y_test using train_test_split from sklearn**\n",
    "This split is made from the train dataset itself.\n",
    "The model is trained on X_train, y_train and tested on X_test and y_test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train.drop('Survived', axis=1),\n",
    "                                                    train['Survived'], test_size=0.20,\n",
    "                                                    random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copied from other notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple approcahes to approcahing this problem.\n",
    "In general, the following steps are performed in creating a framework to operate on the given dataset.\n",
    "1. Determine the relevant packages/libraries involved\n",
    "2. Determine the nature of dataset - tabular/textual\n",
    "3. Nature of operation to be performed: Data Analysis vs Machine Learning/Modelling\n",
    "\n",
    "**Loading the relevant packages as below:**\n",
    "In Python, numpy, pandas, matplotlib and seaborn are the four packages that are needed for most of the data analysis and exploration purposes.\n",
    "These four can be considered to be uploaded by default epecially in cases where data is in tabular format and can be easily represented as  dataframe.\n",
    "\n",
    "**sklearn** is a comprehensive library used for Machine Learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: A Gentle Introduction\n",
    "**A Bird's Eye View: Exploration to obtain an overview**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info ===> R command: str()\n",
    "print(train.info())\n",
    "# This shows that the training dataset has 12 columns.\n",
    "# Total number of rows and columns as well as datatypes of each columns\n",
    "# is also provided here.\n",
    "# This data is also provided in the metadata given on Kaggle.\n",
    "# Survived is the label/output/column which will be predicted for test data.\n",
    "\n",
    "# Printing out the rows and columns using .shape() ===> R command: dim()\n",
    "print(\"\\nTraining Dataset: Rows %s, Columns %s\" %(train.shape[0], train.shape[1]))\n",
    "\n",
    "# Related observations will be made below, after train.head() has been explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info ===> R command: str()\n",
    "print(test.info())\n",
    "# This shows that the test dataset has 11 columns.\n",
    "# Survived is the missing column which will be predicted for test data.\n",
    "\n",
    "# Printing out the rows and columns using .shape() ===> R command: dim()\n",
    "print(\"\\nTest Dataset: Rows %s, Columns %s\" %(test.shape[0], test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring few rows of training dataset\n",
    "# .head() ===> R Command: head()\n",
    "# .tail() ===> R Command: tail()\n",
    "train.head(10)\n",
    "#train.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Small Taste of the Mystery: Some observations**\n",
    "1. PassengerId is assigned to a person. It is expected that there will be a unique PassengerId for each passenger. This will be explored further by comparing the count of unique PassengerIds with the number of rows in the training dataset(891).\n",
    "2. Survived column is the label/output. This column will be separated later into y_train (output) and rest of the dataframe as x_train (input). SInce labels are given for the training dataset, this is a Supervised Learning problem.\n",
    "                           x_train ========== OUR MODEL ============> y_predicted\n",
    "                           Objective: Minimize (y_train - y_predicted) i.e. Training Error\n",
    "    (PLEASE NOTE: This is a very simplistic representaion of training the model. Different issues of bias-variance tradeoff and overfitting will also come into the picture. These will be discussed later. Right now, the goal is to minimize training error to obtain a well trained model.)\n",
    "                                \n",
    "3. Pclass is a categorical variable with 3 values: 1,2,3. This is the same as the concept of factor() and levels in R.\n",
    "4. Name of the passengers: SOme text cleaning and processing may be performed to get insights into survival chances.\n",
    "5. Sex gives the gender. It appears to be a categorical variable with 2 levels.\n",
    "6. Age is a numerical value. It can be converted into a categorical variable later on - dividing the population into different age groups: 0-5, 5-15, 15-30, 30-45, 45-60, 60-100. Also, this column has many missing values.\n",
    "7. SibSp and Parch are also variables with numerical values.\n",
    "8. Ticket gives the ticket number. It may not be a useful variable for our purposes as will be seen later.\n",
    "9. Fare - numerical value. It may be strongly correlated with Pclass also. Thus, it may be left out to avoid overfitting.\n",
    "10. Cabin - The very high number of missing values and the information itself appears to be useless for our purposes.\n",
    "11. Embarked is also a categorical variable. It will need further exploration to determine its usefulness.\n",
    "\n",
    "Overall, it appears clear that the following columns will be important:\n",
    "1. Pclass\n",
    "2. Sex\n",
    "3. Age\n",
    "4. Sibsp\n",
    "5. Parch\n",
    "6. Embarked - 'Lucky, maybe?\n",
    "7. Name - Some information such as title may be derived from it.\n",
    "\n",
    "The following columns can be dropped - \n",
    "1. Ticket\n",
    "2. Fare\n",
    "3. Cabin\n",
    "\n",
    "PassengerId is the index.\n",
    "Survived is the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
